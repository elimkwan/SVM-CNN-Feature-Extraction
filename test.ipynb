{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(arg, testOrtrain):\n",
    "    files = glob.glob(\"./Data/\" + testOrtrain + \" set/\" + arg + \"/*\")\n",
    "    img_arr = []\n",
    "    for f in files:\n",
    "        img_arr.append(cv2.imread(f))\n",
    "        \n",
    "    return np.array(img_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureGetColours(imgs):\n",
    "    g_lowerb = (35,0,0) #green\n",
    "    g_upperb = (90,255,255)\n",
    "    \n",
    "    b_lowerb = (90,0,0) #blue\n",
    "    b_upperb = (135,255,255)\n",
    "    \n",
    "    br_lowerb = (0,0,0) #red/brown\n",
    "    br_upperb = (35,255,255)\n",
    "    \n",
    "    num_pixel = np.prod(imgs[0][:,:,0].size)\n",
    "    f = []\n",
    "    \n",
    "    g, bl, br = [],[],[]\n",
    "    for img in imgs:\n",
    "        dst = img\n",
    "        dst = cv2.cvtColor(dst, cv2.COLOR_BGR2HSV)\n",
    "        green = cv2.inRange(dst, g_lowerb, g_upperb)\n",
    "        blue = cv2.inRange(dst, b_lowerb, b_upperb)\n",
    "        brown = cv2.inRange(dst, br_lowerb, br_upperb)\n",
    "        \n",
    "        green_pixel = cv2.countNonZero(green)\n",
    "        blue_pixel = cv2.countNonZero(blue)\n",
    "        brown_pixel = cv2.countNonZero(brown)\n",
    "        \n",
    "        k = [0]*3\n",
    "        k[0] = 1 if (green_pixel/num_pixel > 0.3) else 0\n",
    "        k[1] = 1 if (blue_pixel/num_pixel > 0.3) else 0\n",
    "        k[2] = 1 if (brown_pixel/num_pixel > 0.3) else 0\n",
    "\n",
    "        g.append(green_pixel/num_pixel)\n",
    "        bl.append(blue_pixel/num_pixel)\n",
    "        br.append(brown_pixel/num_pixel)\n",
    "    \n",
    "    return g,bl,br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dominant Line Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureHaveDominantLine(imgs):\n",
    "    minLineLength = 40\n",
    "    maxLineGap = 10\n",
    "    f = []\n",
    "    for index,img in enumerate(imgs):\n",
    "        dst = cv2.bilateralFilter(img,9, 75, 75, cv2.BORDER_DEFAULT)\n",
    "        gray = cv2.cvtColor(dst,cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray,80,200,apertureSize = 3)\n",
    "        lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "\n",
    "        k=0\n",
    "        if lines is not None and lines.shape[0] > 2:\n",
    "            k=1\n",
    "            \n",
    "#             img2 = img.copy()\n",
    "#             for i in range(0, len(lines)):\n",
    "#                 l= lines[i][0]\n",
    "#                 cv2.line(img2, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, 8)\n",
    "#             name = \"test/houghlines\" + str(index) + \".jpg\"\n",
    "#             cv2.imwrite(name,img2)\n",
    "            \n",
    "        f.append(k)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angles of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_angle(arr):\n",
    "#     return arr[1]\n",
    "    if arr[1] == arr[3]:\n",
    "        return np.pi/2\n",
    "    if arr[0] == arr[2]:\n",
    "        return 0\n",
    "    \n",
    "    if arr[1] > arr[3]:\n",
    "        p1 = [arr[0], arr[1]]\n",
    "        p2 = [arr[2], arr[3]]\n",
    "    else:\n",
    "        p1 = [arr[2], arr[3]]\n",
    "        p2 = [arr[0], arr[1]]\n",
    "    \n",
    "    dy = p2[1]-p1[1]\n",
    "    dx = p2[0]-p1[0]\n",
    "    return np.arctan(dy/dx)\n",
    "\n",
    "\n",
    "def FeatureHaveHorizontalVerticalDiagLine(imgs):\n",
    "    minLineLength = 40\n",
    "    maxLineGap = 10\n",
    "    f = []\n",
    "    h,v,d =[],[],[]\n",
    "    for index, img in enumerate(imgs):\n",
    "        dst = cv2.bilateralFilter(img,9, 75, 75, cv2.BORDER_DEFAULT)\n",
    "        gray = cv2.cvtColor(dst,cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray,80,200,apertureSize = 3)\n",
    "        lines = cv2.HoughLinesP(edges,1,np.pi/180,60,minLineLength,maxLineGap)\n",
    "        a = []\n",
    "        k = img.copy()\n",
    "        if lines is not None:\n",
    "            for i in range(0, len(lines)):\n",
    "                l= lines[i][0]\n",
    "                a.append(cal_angle(l))\n",
    "#                 cv2.line(k, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, 8)\n",
    "#                 cv2.line(k, Point(lines[i][0], lines[i][1]),Point( lines[i][2], lines[i][3]), Scalar(0,0,255), 3, 8 );\n",
    "            \n",
    "#             name = \"test/houghlines\" + str(index) + \".jpg\"\n",
    "#             cv2.imwrite(name,k)\n",
    "            a = np.array(a)\n",
    "            \n",
    "            vertical = np.count_nonzero(np.logical_and(a > -0.61, a < 0.61))/a.shape[0]\n",
    "            horizontal = np.count_nonzero(np.logical_and(a >= 1.22, a < 1.92))/a.shape[0]\n",
    "            diag = np.logical_or(np.logical_and(a >= 0.69, a < 0.87),np.logical_and(a >= 2.26893, a < 2.44346))\n",
    "            diagonal = np.count_nonzero(diag)/a.shape[0]\n",
    "            \n",
    "            h.append(horizontal)\n",
    "            v.append(vertical)\n",
    "            d.append(diagonal)\n",
    "            \n",
    "        else:\n",
    "            h.append(0)\n",
    "            v.append(0)\n",
    "            d.append(0)\n",
    "        \n",
    "        \n",
    "    return h,v,d\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareInput(extracted_data):\n",
    "    y_labels = [1,2,3,4]\n",
    "    x,y = [],[]\n",
    "    f = [None]*7\n",
    "    num_feature = 7\n",
    "    \n",
    "    for i in range(4):\n",
    "        f[0],f[1],f[2] = FeatureGetColours(extracted_data[i])\n",
    "        f[3] = FeatureHaveDominantLine(extracted_data[i])\n",
    "        f[4],f[5],f[6] = FeatureHaveHorizontalVerticalDiagLine(extracted_data[i])\n",
    "        \n",
    "        k = np.column_stack([f[0],f[1],f[2],f[3],f[4],f[5],f[6]])\n",
    "\n",
    "        x.append(k)\n",
    "        y.append(np.tile(i,(k.shape[0],1)))\n",
    "\n",
    "    x_train = np.vstack((x[0],x[1],x[2],x[3]))\n",
    "    y_train = np.vstack((y[0],y[1],y[2],y[3]))\n",
    "    x_train = np.asarray(x_train, np.float32)\n",
    "    y_train = np.asarray(y_train, np.int32)\n",
    "\n",
    "    return x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareInput_comb(extracted_data): # only the first four features\n",
    "    y_labels = [1,2,3,4]\n",
    "    x,y = [],[]\n",
    "    f = [None]*7\n",
    "    num_feature = 7\n",
    "    \n",
    "    for i in range(4):\n",
    "        f[0],f[1],f[2] = FeatureGetColours(extracted_data[i])\n",
    "        f[3] = FeatureHaveDominantLine(extracted_data[i])\n",
    "        \n",
    "        k = np.column_stack([f[0],f[1],f[2],f[3]])\n",
    "\n",
    "        x.append(k)\n",
    "        y.append(np.tile(i,(k.shape[0],1)))\n",
    "\n",
    "    x_train = np.vstack((x[0],x[1],x[2],x[3]))\n",
    "    y_train = np.vstack((y[0],y[1],y[2],y[3]))\n",
    "    x_train = np.asarray(x_train, np.float32)\n",
    "    y_train = np.asarray(y_train, np.int32)\n",
    "    return x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareInput_single(extracted_data, feature):\n",
    "    y_labels = [1,2,3,4]\n",
    "\n",
    "    x,y = [],[]\n",
    "    f = [None]*7\n",
    "    for i in range(4): #number of catergories\n",
    "        f[0],f[1],f[2] = FeatureGetColours(extracted_data[i])\n",
    "        f[3] = FeatureHaveDominantLine(extracted_data[i])\n",
    "        f[4],f[5],f[6] = FeatureHaveHorizontalVerticalDiagLine(extracted_data[i])\n",
    "        \n",
    "        x.extend(f[feature])\n",
    "        y.append(np.tile(i,(len(f[0]),1)))\n",
    "\n",
    "    y_train = np.vstack((y[0],y[1],y[2],y[3]))\n",
    "    x_train = np.asarray(x, np.float32)\n",
    "    y_train = np.asarray(y_train, np.int32)\n",
    "    return x_train,y_train\n",
    "\n",
    "# prepareInput_single(extracted_data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(x_train,y_train, kernel = \"LINEAR\"):\n",
    "    svm = cv2.ml.SVM_create()\n",
    "    svm.setType(cv2.ml.SVM_C_SVC)\n",
    "    \n",
    "    k = cv2.ml.SVM_LINEAR\n",
    "    if (kernel == \"RBF\"):\n",
    "        k = cv2.ml.SVM_RBF\n",
    "    elif (kernel == \"POLY\"):\n",
    "        k = 1\n",
    "        svm.setDegree(2.0)\n",
    "\n",
    "    svm.setKernel(k)\n",
    "    \n",
    "    svm.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-6))\n",
    "    svm.train(x_train, cv2.ml.ROW_SAMPLE, y_train)\n",
    "    return svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(x_train, y_train, model):\n",
    "    _, response = model.predict(x_train)\n",
    "    f1 = f1_score(y_train, response, average='macro')\n",
    "    count = np.equal(response,y_train)\n",
    "    a = np.count_nonzero(count)/len(y_train)\n",
    "    print(\"Accuracy\", a)\n",
    "    print(\"F1\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-modal model (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "catergories = [\"bridge\",\"coast\",\"mountain\",\"rainforest\"]\n",
    "extracted_data = []\n",
    "testing_data = []\n",
    "for c in catergories:\n",
    "    extracted_data.append(load_data(c,\"Training\"))\n",
    "    testing_data.append(load_data(c,\"Testing\"))\n",
    "\n",
    "x_train,y_train = prepareInput(extracted_data)\n",
    "x_test,y_test = prepareInput(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = x_train[:,0]\n",
    "f1 = x_train[:,5]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "for cat in range(4):\n",
    "    catergories = [\"bridge\",\"coast\",\"mountain\",\"rainforest\"]\n",
    "    i = (y_train == cat)\n",
    "    ax.scatter(f0[i[:,0]], f1[i[:,0]], label=catergories[cat])\n",
    "\n",
    "# ax.set_title(\"PCA of the 1st and 2nd Component\")\n",
    "ax.set_xlabel(\"Feature: Detected Number of Green Pixels / Total Number of Pixels\")\n",
    "ax.set_ylabel(\"Feature: Detected Number of Horizontal Line / Total Number of Lines\")\n",
    "legend = ax.legend(loc='upper left', bbox_to_anchor=(1.1, 1))\n",
    "\n",
    "# fig.savefig(\"linear-data.jpeg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_multi = trainModel(x_train,y_train, \"LINEAR\")\n",
    "getAccuracy(x_train, y_train, svm_multi) \n",
    "getAccuracy(x_test, y_test, svm_multi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svm_multi = trainModel(x_train,y_train, \"POLY\")\n",
    "getAccuracy(x_train, y_train, svm_multi) \n",
    "getAccuracy(x_test, y_test, svm_multi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7454545454545455\n",
      "F1 0.7454048578374995\n",
      "Accuracy 0.6714285714285714\n",
      "F1 0.669492360074227\n"
     ]
    }
   ],
   "source": [
    "svm_multi1 = trainModel(x_train,y_train, \"RBF\")\n",
    "getAccuracy(x_train, y_train, svm_multi1) \n",
    "getAccuracy(x_test, y_test, svm_multi1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[3.]]\n",
      "[[1.]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "def load_self_data(num_feat):\n",
    "    files = glob.glob(\"./self-data/*\")\n",
    "    img = []\n",
    "    for fi in files:\n",
    "        img.append(cv2.imread(fi))\n",
    "        \n",
    "#     print(img_arr.shape)\n",
    "    img_arr = np.array(img)\n",
    "    y_label = [0,3,2,1] \n",
    "    \n",
    "    f = [None]*7\n",
    "    for i in range(img_arr.shape[0]):\n",
    "        pic = img_arr[i]\n",
    "        pic = pic.reshape((1,256,256,3))\n",
    "        f[0],f[1],f[2] = FeatureGetColours(pic)\n",
    "        f[3] = FeatureHaveDominantLine(pic)\n",
    "        f[4],f[5],f[6] = FeatureHaveHorizontalVerticalDiagLine(pic)\n",
    "        x = np.array(f).reshape((1,7)).astype(np.float32)\n",
    "        y = np.array(i).reshape((1,1)).astype(np.int32)\n",
    "#         getAccuracy(x, y, svm_multi1)\n",
    "        _, response = svm_multi1.predict(x)\n",
    "        print(response)\n",
    "    \n",
    "    return img_arr\n",
    "\n",
    "own_img = load_self_data(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-modal model (first 4 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6272727272727273\n",
      "F1 0.6226615671295629\n",
      "Accuracy 0.6142857142857143\n",
      "F1 0.6107979126108588\n"
     ]
    }
   ],
   "source": [
    "# catergories = [\"bridge\",\"coast\",\"mountain\",\"rainforest\"]\n",
    "# extracted_data = []\n",
    "# testing_data = []\n",
    "# for c in catergories:\n",
    "#     extracted_data.append(load_data(c,\"Training\"))\n",
    "#     testing_data.append(load_data(c,\"Testing\"))\n",
    "\n",
    "x_train,y_train = prepareInput_comb(extracted_data)\n",
    "x_test,y_test = prepareInput_comb(testing_data)\n",
    "svm_multi = trainModel(x_train,y_train, \"LINEAR\")\n",
    "getAccuracy(x_train, y_train, svm_multi) \n",
    "getAccuracy(x_test, y_test, svm_multi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_multi = trainModel(x_train,y_train, \"POLY\")\n",
    "getAccuracy(x_train, y_train, svm_multi) \n",
    "getAccuracy(x_test, y_test, svm_multi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6651515151515152\n",
      "F1 0.6639676306121294\n",
      "Accuracy 0.6642857142857143\n",
      "F1 0.6637663740245262\n"
     ]
    }
   ],
   "source": [
    "svm_multi2 = trainModel(x_train,y_train, \"RBF\")\n",
    "getAccuracy(x_train, y_train, svm_multi2) \n",
    "getAccuracy(x_test, y_test, svm_multi2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[[3.]]\n",
      "[[2.]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "def load_self_data(num_feat):\n",
    "    files = glob.glob(\"./self-data/*\")\n",
    "    img = []\n",
    "    for fi in files:\n",
    "        img.append(cv2.imread(fi))\n",
    "        \n",
    "#     print(img_arr.shape)\n",
    "    img_arr = np.array(img)\n",
    "    \n",
    "    y_label = [0,3,2,1] \n",
    "    f = [None]*4\n",
    "    for i in range(img_arr.shape[0]):\n",
    "        pic = img_arr[i]\n",
    "        pic = pic.reshape((1,256,256,3))\n",
    "        f[0],f[1],f[2] = FeatureGetColours(pic)\n",
    "        f[3] = FeatureHaveDominantLine(pic)\n",
    "#         f[4],f[5],f[6] = FeatureHaveHorizontalVerticalDiagLine(pic)\n",
    "        x = np.array(f).reshape((1,4)).astype(np.float32)\n",
    "        y = np.array(y_label[i]).reshape((1,1)).astype(np.int32)\n",
    "#         getAccuracy(x, y, svm_multi2)\n",
    "        _, response = svm_multi2.predict(x)\n",
    "        print(response)\n",
    "    \n",
    "    return img_arr\n",
    "\n",
    "own_img = load_self_data(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-modal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in range(0,7):\n",
    "    print(\"\\n Training with feature\", feature)\n",
    "    x_train,y_train = prepareInput_single(extracted_data,feature)\n",
    "    x_test,y_test = prepareInput_single(testing_data,feature)\n",
    "    print(\"\\n Linear\")\n",
    "    svm_multi = trainModel(x_train,y_train,\"LINEAR\")\n",
    "    getAccuracy(x_train, y_train, svm_multi) \n",
    "    getAccuracy(x_test, y_test, svm_multi) \n",
    "    print(\"\\n POLY\")\n",
    "    svm_multi = trainModel(x_train,y_train,\"POLY\")\n",
    "    getAccuracy(x_train, y_train, svm_multi) \n",
    "    getAccuracy(x_test, y_test, svm_multi) \n",
    "    print(\"\\n RBF\")\n",
    "    svm_multi = trainModel(x_train,y_train,\"RBF\")\n",
    "    getAccuracy(x_train, y_train, svm_multi) \n",
    "    getAccuracy(x_test, y_test, svm_multi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = prepareInput_single(extracted_data,4)\n",
    "f0 = x_train\n",
    "f1 = [0]*len(f0)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "for cat in range(4):\n",
    "    catergories = [\"bridge\",\"coast\",\"mountain\",\"rainforest\"]\n",
    "    i = (y_train == cat)\n",
    "    ax.yaxis.set_ticks(np.arange(0,4,1))\n",
    "    ax.scatter(f0, y_train, color= \"green\")\n",
    "\n",
    "plt.yticks([0, 1, 2, 3], [\"bridge\",\"coast\",\"mountain\",\"rainforest\"])\n",
    "ax.set_xlabel(\"Feature 4: Number of Horizontal Lines / Total Number of Lines\")\n",
    "ax.set_ylabel(\"Classes\")\n",
    "legend = ax.legend(loc='upper left', bbox_to_anchor=(1.1, 1))\n",
    "\n",
    "fig.savefig(\"linear-data2.jpeg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,y_train = prepareInput_single(extracted_data,5)\n",
    "f0 = x_train\n",
    "f1 = [0]*len(f0)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "for cat in range(4):\n",
    "    catergories = [\"bridge\",\"coast\",\"mountain\",\"rainforest\"]\n",
    "    i = (y_train == cat)\n",
    "    ax.yaxis.set_ticks(np.arange(0,4,1))\n",
    "    ax.scatter(f0, y_train, color = \"blue\")\n",
    "\n",
    "plt.yticks([0, 1, 2, 3], [\"bridge\",\"coast\",\"mountain\",\"rainforest\"])\n",
    "ax.set_xlabel(\"Feature 5: Number of Vertical Lines / Total Number of Lines\")\n",
    "ax.set_ylabel(\"Classes\")\n",
    "legend = ax.legend(loc='upper left', bbox_to_anchor=(1.1, 1))\n",
    "\n",
    "fig.savefig(\"linear-data2.jpeg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = prepareInput_single(extracted_data,6)\n",
    "f0 = x_train\n",
    "f1 = [0]*len(f0)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "for cat in range(4):\n",
    "    catergories = [\"bridge\",\"coast\",\"mountain\",\"rainforest\"]\n",
    "    i = (y_train == cat)\n",
    "    ax.yaxis.set_ticks(np.arange(0,4,1))\n",
    "    ax.scatter(f0, y_train, color = \"grey\")\n",
    "\n",
    "plt.yticks([0, 1, 2, 3], [\"bridge\",\"coast\",\"mountain\",\"rainforest\"])\n",
    "ax.set_xlabel(\"Feature 6: Number of Diagonal Lines / Total Number of Lines\")\n",
    "ax.set_ylabel(\"Classes\")\n",
    "legend = ax.legend(loc='upper left', bbox_to_anchor=(1.1, 1))\n",
    "\n",
    "fig.savefig(\"linear-data2.jpeg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension: CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout, Conv3D,MaxPooling3D, Conv2D, MaxPooling2D, Dense, Reshape,Flatten\n",
    "from functools import partial\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_small(arg, testOrtrain):\n",
    "    files = glob.glob(\"./Data/\" + testOrtrain + \" set/\" + arg + \"/*\")\n",
    "    img_arr = []\n",
    "    for f in files:\n",
    "        i = cv2.imread(f)\n",
    "        height, width, channel = i.shape[:3]\n",
    "        i = cv2.resize(i,None,fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC)\n",
    "        img_arr.append(i)\n",
    "        \n",
    "    return np.array(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catergories = [\"bridge\",\"coast\",\"mountain\",\"rainforest\"]\n",
    "extracted_data = []\n",
    "val_data = []\n",
    "testing_data = []\n",
    "for c in catergories:\n",
    "    all_training = load_data_small(c,\"Training\")\n",
    "    sz = int(all_training.shape[0]*0.8)   \n",
    "    extracted_data.append(all_training[:sz])\n",
    "    val_data.append(all_training[sz:])\n",
    "    testing_data.append(load_data_small(c,\"Testing\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatCNNInput(data):\n",
    "    x = np.array(data)\n",
    "    num_catergories = x.shape[1]\n",
    "    x_train = x.reshape((x.shape[0]*x.shape[1], x.shape[2], x.shape[3], x.shape[4], 1))\n",
    "\n",
    "    y = []\n",
    "    for i in range(4):\n",
    "        y.append(np.tile(i,(num_catergories,1)))\n",
    "    y_train = np.vstack((y[0],y[1],y[2],y[3]))\n",
    "    \n",
    "    return x_train, y_train\n",
    "\n",
    "x_train, y_train = formatCNNInput(extracted_data)\n",
    "x_val, y_val = formatCNNInput(val_data)\n",
    "x_test, y_test = formatCNNInput(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    Conv3D(filters=32, kernel_size=(4,4,1), input_shape=(128,128, 3, 1)),\n",
    "    keras.layers.MaxPooling3D(pool_size=(2,2,3)),\n",
    "    Reshape((62,62,32)),\n",
    "    Conv2D(filters=8, kernel_size=12),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=8, kernel_size=4),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=4, kernel_size=4),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(units=4, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"Trained_Model/training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.Nadam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Nadam'\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    optimizer=optim,\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        batch_size=64,\n",
    "                        epochs=30,\n",
    "                        validation_data = (x_val, y_val),\n",
    "                        callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"Trained_Model/cnn_classifier3/cnn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
